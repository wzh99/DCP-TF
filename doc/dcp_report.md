# GPU 计算及深度学习 大作业报告

###### 王梓涵　517021911179

## 简介

本项目使用 TensorFlow 实现了神经网络模型 [Deep Closest Point](https://arxiv.org/abs/1905.03304) 以求解点云配准问题，使用 [TensorFlow Graphics](https://tensorflow.google.cn/graphics) 生成点云的刚体变换。

## 实现

### 生成数据

本项目中的原始模型来自现有的数据集，而刚体变换数据以及变换后的点云数据则需要自行生成。由于神经网络中数据是分批输入的，数据的生成也是按照批为单位进行。这里采用的是随机的生成策略，即对于每一批中的每一个点云模型，都单独为其生成一组随机的刚体变换，同时计算变换后的模型。刚体变换和变换后的模型只在其被需要的时候生成，在内存中并不作长久保留。这样保证了在每一轮训练/测试中，每个模型的变换都是不同的。这一方法使得数据大大增强，基本消除了模型出现过拟合的可能。

在具体实现中，通过重载 Keras 中的 `Sequence` 类来组织数据，具体的生成过程通过重载 `__getitem__()` 函数来实现。以下假设一批源点云数据的张量形状为 `(batch_size, num_points, 3)`。一个刚体变换具有六个自由度，旋转及平移各三个。首先使用 `numpy` 为每个模型生成三个 $[-\pi,\pi]$ 之间的随机数作为欧拉角的三个分量，张量形状为 `(batch_size, 1, 3)`。使用 TFG 中的 `rotation_matrix_3d.from_euler()` 将欧拉角转为旋转变换矩阵，张量形状为 `(batch_size, 1, 3, 3)`。使用 TFG 中的 `rotation_matrix_3d.rotate()` 对源点云进行旋转变换。再为每个模型生成三个 $[-0.5,0.5]$ 之间的随机数作为平移分量，张量形状为 `(batch_size, 1, 3)`。将之与变换后的点云做加法运算，即可得到变换后的目标点云，张量形状与源点云相同。

在生成所有数据后，需要对数据进行重新组织，使其适合作为模型输入。模型的输入包含源点云和目标点云，所以将这两组数据分别在第二维上扩张维度，然后在第二维上连接，张量形状为 `(batch_size, 2, num_points, 3)`。模型的输出为刚体变换，本项目中采取的方法是将旋转分量的第二维挤压，然后将其与平移分量在第二维上连接，张量形状为 `(batch_size, 4, 3)`。这一组织方式不符合常规的齐次变换矩阵，但其构造方式更加直接。

### 构建模型

DCP 模型较为复杂，包含了三个主要的模块：负责特征提取的 DGCNN，负责序列匹配的 Transformer，以及基于奇异值分解（SVD）的刚体变换生成模块。这里仅对各模块中的实现要点进行解释，不会覆盖所有模型的细节。

#### DGCNN

DGCNN 全称为动态图卷积神经网络（Dynamic Graph CNN），其将点云数据建模为图，对于点云中的每个点（即图中的每个顶点），将其与该点的 k 近邻点相连作为图的边，通过边卷积（EdgeConv）来提取各点的特征。

## 实验

### 输入数据



### 训练与验证



### 配准方法比较

| 方法   | 误差值 | 耗时（秒） |
| ------ | ------ | ---------- |
| DCP    | 0.193  | 0.670      |
| ICP    | 6.066  | 0.027      |
| 4-PCS  | 6.132  | 0.077      |
| Go-ICP | 1.534  | 2.384      |

